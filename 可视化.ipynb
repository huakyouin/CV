{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import package\n",
    "import package.optim as optim\n",
    "import package.loss as loss\n",
    "import sys\n",
    "import router as mn\n",
    "import package.draw as draw\n",
    "import itertools\n",
    "\n",
    "## 文件路径\n",
    "train_file = sys.path[0]+'/MNIST/trainset.npz'\n",
    "param_file = sys.path[0]+'/MNIST/param.npz'\n",
    "test_file = sys.path[0]+'/MNIST/testset.npz'\n",
    "record_file = sys.path[0]+'/record.txt'\n",
    "\n",
    "## 设置网络\n",
    "def quick_net(a):\n",
    "    layers = [\n",
    "            {'type': 'batchnorm', 'shape': 784, 'requires_grad': False, 'affine': False},\n",
    "            {'type': 'linear', 'shape': (784, a)},  # 输入->第一层隐含层\n",
    "            {'type': 'batchnorm', 'shape': a},\n",
    "            {'type': 'relu'},\n",
    "            {'type': 'linear', 'shape': (a, 10)}, # 最后一层->输出\n",
    "        ]\n",
    "    net = package.Net(layers)\n",
    "    return net\n",
    "net=quick_net(350)\n",
    "## 设置损失函数\n",
    "loss_fn = loss.CrossEntropyLoss()\n",
    "## 设置批大小\n",
    "batch_size = 128\n",
    "## 设置优化器\n",
    "optimizer = optim.RMSprpo(net.parameters, lr=1e-3,penalty=5e-6,decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最优参数下模型训练及精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率:96.70%\n"
     ]
    }
   ],
   "source": [
    "mn.train(net, loss_fn, train_file, batch_size, optimizer,\\\n",
    "    load_file=None, save_path=param_file, times=4,silent=True)\n",
    "tacc,tloss=mn.test(net,loss_fn,test_file,None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注：这一代码块相当慢,可以的请跳过该块，用保存好的数据",
    "from router import *\n",
    "## 修改train函数，使迭代中记录可视化信息\n",
    "def train_vis(net, loss_fn, train_file,test_file, batch_size, optimizer, load_file=None,\\\n",
    "     save_path=None, times=1,go_on=False,silent=False):\n",
    "    X, Y = load_MNIST(train_file, transform=True)   # 加载训练样本和真实标签\n",
    "    Xt, Yt = load_MNIST(test_file, transform=True)\n",
    "    data_size = X.shape[0]   # 样本数\n",
    "    ## 如果属于继续训练就加载参数\n",
    "    if go_on and load_file is not None and os.path.isfile(load_file): load(net.parameters, load_file) \n",
    "    ## 根据times轮次设置循环数\n",
    "    trainacc=[];testloss=[];testacc=[]\n",
    "    for loop in range(times):  \n",
    "        i = 0 # i 为样本中该轮已经训练过的数量\n",
    "        ## 按batch_size分批训练\n",
    "        while i <= data_size - batch_size:\n",
    "            x = X[i:i+batch_size]\n",
    "            y = Y[i:i+batch_size]\n",
    "            i += batch_size\n",
    "            ## 前向传播\n",
    "            output = net.forward(x)  \n",
    "            ## 根据损失函数计算损失            \n",
    "            batch_acc, batch_loss = loss_fn(output, y)  \n",
    "            # print(batch_loss)\n",
    "            ## 梯度反向传播\n",
    "            eta = loss_fn.gradient()\n",
    "            net.backward(eta)\n",
    "            ## 用优化器进行参数学习\n",
    "            optimizer.update()\n",
    "            ## 记录可视化信息\n",
    "            train_acc,_=test(net,loss_fn,get=[X,Y],silent=True)\n",
    "            test_acc,test_loss=test(net,loss_fn,get=[Xt,Yt],silent=True)\n",
    "            trainacc.append(train_acc)\n",
    "            testacc.append(test_acc)\n",
    "            testloss.append(test_loss)\n",
    "            ## 每50次迭代打印以下训练信息\n",
    "            if i % 50 == 0 and not silent:\n",
    "                print(\"loop: %d, batch: %5d, batch acc: %2.1f, batch loss: %.2f\" % \\\n",
    "                    (loop+1, i, batch_acc*100, batch_loss))\n",
    "    ## 如果传入保存路径，就对参数进行保存\n",
    "    if save_path is not None: save(net.parameters, save_path)\n",
    "    return trainacc,testacc,testloss\n",
    "\n",
    "a,b,c=train_vis(net, loss_fn, train_file,test_file, batch_size, optimizer,times=2,silent=True)\n",
    "np.savez(sys.path[0]+'/MNIST/plotinfo',trainacc=a,testacc=b,testloss=c)\n",
    "# 注：这一代码块相当慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "from package.draw import draw_ts\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (5.0, 3.0) # 显示大小\n",
    "file=np.load(sys.path[0]+'/MNIST/plotinfo.npz')\n",
    "a=file['trainacc'];b=file['testacc'];c=file['testloss']\n",
    "draw_ts([a,b],['训练集精度','测试集精度'])\n",
    "draw_ts([c],['测试集损失'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络参数可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "from package.draw import draw_ts\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (5.0, 3.0) # 显示大小\n",
    "net=quick_net(350)\n",
    "mn.load(net.parameters, param_file) \n",
    "W=mn.read_weight(net.parameters)\n",
    "W1 = W[0]\n",
    "W2 = W[2]\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(W1)\n",
    "pca_W1 = pca.fit_transform(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 4.0) # 显示大小\n",
    "plt.subplots_adjust(hspace=0, wspace=0.1)\n",
    "for i in range(pca_W1.shape[1]):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(pca_W1[:, i].reshape(28, 28,order='F'), cmap ='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 6.0) # 显示大小\n",
    "for i in range(W2.shape[1]):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(W2[:, i].reshape(25,14), cmap ='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 6.0) # 显示大小\n",
    "nW2=pca.fit_transform(W2.T).T\n",
    "plt.imshow(nW2,cmap='gray')\n",
    "# plt.axis('off')\n",
    "plt.ylabel('hidden')\n",
    "plt.xlabel('output')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "535d0d05661be4f74dc627d25ce397fa25bdff20d000e5cf53c6f3c32021f41a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
